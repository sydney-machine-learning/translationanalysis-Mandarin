{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-docx) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-docx) (4.9.0)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Using cached googletrans-4.0.0rc1-py3-none-any.whl\n",
      "Requirement already satisfied: httpx==0.13.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Requirement already satisfied: hstspreload in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.1.1)\n",
      "Requirement already satisfied: idna==2.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
      "Requirement already satisfied: chardet==3.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
      "Requirement already satisfied: h2==3.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
      "Installing collected packages: googletrans\n",
      "  Attempting uninstall: googletrans\n",
      "    Found existing installation: googletrans 3.0.0\n",
      "    Uninstalling googletrans-3.0.0:\n",
      "      Successfully uninstalled googletrans-3.0.0\n",
      "Successfully installed googletrans-4.0.0rc1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    file_path = f'/Users/wangxuechun/Desktop/Julia_Lovell_the_true_story_of_Ahq/Julia_lovell_version_chapt{i}.docx'\n",
    "\n",
    "    doc = Document(file_path)\n",
    "    paragraphs = [para.text for para in doc.paragraphs if para.text.strip() != \"\"]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(paragraphs, columns=[f'English_Verse_chap{i}_julia'])\n",
    "\n",
    "    df = df.drop(df.index[0])\n",
    "\n",
    "    csv_path = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/julia_dataset/chapter_{i}_eng_version_julia.csv'\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator, LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google \n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "# Loop through the chapters\n",
    "for i in range(1, 10):\n",
    "    # Construct the file path for the current chapter\n",
    "    file_path_google = f'/Users/wangxuechun/Desktop/Chinese_Version_The_true_story_of_Ah_q/Chinese_version_the_true_story_of_Ah_q_chapt{i}.docx'\n",
    "\n",
    "    doc_google = Document(file_path_google)\n",
    "\n",
    "    paragraphs = [para.text for para in doc_google.paragraphs if para.text.strip() != \"\"]\n",
    "\n",
    "    df = pd.DataFrame(paragraphs, columns=['Paragraphs'])\n",
    "    \n",
    "    # Define a translation function with error handling\n",
    "    def translate_text(text):\n",
    "        try:\n",
    "            translated = translator.translate(text, src='zh-cn', dest='en')\n",
    "            return translated.text\n",
    "        except Exception as e:\n",
    "            return f\"Error: {e}\"\n",
    "    \n",
    "    # Apply the translation function to each paragraph\n",
    "    df[f'English_Verse_chap{i}_google'] = df['Paragraphs'].apply(translate_text)\n",
    "    \n",
    "    # Drop the original Paragraphs column\n",
    "    df = df.drop(columns=['Paragraphs'])\n",
    "    \n",
    "    # Construct the path to save the CSV file\n",
    "    csv_path = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/google_dataset/chapter_{i}_eng_version_google.csv'\n",
    "    \n",
    "    # Save the translated text to a CSV file\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsien dataset extraction\n",
    "for i in range(1,10):\n",
    "    file_path = f'/Users/wangxuechun/Desktop/Hsien_version_the_true_story_of_Ah_Q/Hsien_version_the_true_story_of_Ah_Q_chapter{i}.docx'\n",
    "\n",
    "    doc = Document(file_path)\n",
    "    paragraphs = [para.text for para in doc.paragraphs if para.text.strip() != \"\"]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(paragraphs, columns=[f'English_Verse_chap{i}_hsien'])\n",
    "\n",
    "\n",
    "    csv_path = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/hsien_dataset/chapter_{i}_eng_version_hsien.csv'\n",
    "\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data merge\n",
    "def agg(x):\n",
    "    if x.dtype == 'object':\n",
    "        return ' '.join(x)\n",
    "    else:\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsien_chapt1 = pd.read_csv(\"/Users/wangxuechun/unsw/thesis-repo/Data_set/hsien_dataset/chapter_1_eng_version_hsien.csv\")\n",
    "merged_rows_hsien_chapt1=df_hsien_chapt1.iloc[5:7]\n",
    "merged_row_hsien_chapt1 = merged_rows_hsien_chapt1.agg(agg)\n",
    "\n",
    "original_indices_hsien_chapt1 = merged_rows_hsien_chapt1.index\n",
    "\n",
    "insert_index_hsien_chapt1 = original_indices_hsien_chapt1[0]\n",
    "\n",
    "df_dropped = df_hsien_chapt1.drop(original_indices_hsien_chapt1)\n",
    "\n",
    "merged_row_df_hsien_chapt1 = pd.DataFrame([merged_row_hsien_chapt1], index=[insert_index_hsien_chapt1])\n",
    "\n",
    "df_with_merged_hsien_chapt1 = pd.concat([df_dropped.iloc[:insert_index_hsien_chapt1], merged_row_df_hsien_chapt1, df_dropped.iloc[insert_index_hsien_chapt1:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "csv_path_hsien_chapt1 = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/hsien_dataset/chapter_1_eng_version_hsien.csv'\n",
    "df_with_merged_hsien_chapt1.to_csv(csv_path_hsien_chapt1, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_julia_chapt1 = pd.read_csv(\"/Users/wangxuechun/unsw/thesis-repo/Data_set/julia_dataset/chapter_1_eng_version_julia.csv\")\n",
    "#first merge\n",
    "merged_rows_julia_chapt1 = df_julia_chapt1.iloc[1:3]\n",
    "merged_row_julia_chapt1 = merged_rows_julia_chapt1.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt1 = merged_rows_julia_chapt1.index\n",
    "\n",
    "insert_index_julia_chapt1 = original_indices_julia_chapt1[0]\n",
    "\n",
    "df_dropped_julia = df_julia_chapt1.drop(original_indices_julia_chapt1)\n",
    "\n",
    "merged_row_df_julia_chapt1 = pd.DataFrame([merged_row_julia_chapt1], index=[insert_index_julia_chapt1])\n",
    "\n",
    "df_with_merged_julia_chapt1 = pd.concat([df_dropped_julia.iloc[:insert_index_julia_chapt1], merged_row_df_julia_chapt1, df_dropped_julia.iloc[insert_index_julia_chapt1:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "#second merge\n",
    "merged_rows_julia_chapt1 = df_with_merged_julia_chapt1[2:4]\n",
    "\n",
    "merged_row_julia_chapt1 = merged_rows_julia_chapt1.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt1 = merged_rows_julia_chapt1.index\n",
    "\n",
    "insert_index_julia_chapt1 = original_indices_julia_chapt1[0]\n",
    "\n",
    "df_dropped_julia = df_with_merged_julia_chapt1.drop(original_indices_julia_chapt1)\n",
    "\n",
    "merged_row_df_julia_chapt1 = pd.DataFrame([merged_row_julia_chapt1], index=[insert_index_julia_chapt1])\n",
    "\n",
    "df_with_merged_julia_chapt1 = pd.concat([df_dropped_julia.iloc[:insert_index_julia_chapt1], merged_row_df_julia_chapt1, df_dropped_julia.iloc[insert_index_julia_chapt1:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#third merge\n",
    "merged_rows_julia_chapt1 = df_with_merged_julia_chapt1[5:7]\n",
    "\n",
    "merged_row_julia_chapt1 = merged_rows_julia_chapt1.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt1 = merged_rows_julia_chapt1.index\n",
    "\n",
    "insert_index_julia_chapt1 = original_indices_julia_chapt1[0]\n",
    "\n",
    "df_dropped_julia = df_with_merged_julia_chapt1.drop(original_indices_julia_chapt1)\n",
    "\n",
    "merged_row_df_julia_chapt1 = pd.DataFrame([merged_row_julia_chapt1], index=[insert_index_julia_chapt1])\n",
    "\n",
    "df_with_merged_julia_chapt1 = pd.concat([df_dropped_julia.iloc[:insert_index_julia_chapt1], merged_row_df_julia_chapt1, df_dropped_julia.iloc[insert_index_julia_chapt1:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "#save to csv \n",
    "csv_path_julia_chapt1 = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/julia_dataset/chapter_1_eng_version_julia.csv'\n",
    "df_with_merged_julia_chapt1.to_csv(csv_path_julia_chapt1, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chapter 2\n",
    "df_hsien_chapt2 = pd.read_csv(\"/Users/wangxuechun/unsw/thesis-repo/Data_set/hsien_dataset/chapter_2_eng_version_hsien.csv\")\n",
    "#hsien merge\n",
    "merged_rows_hsien_chapt2 = df_hsien_chapt2.iloc[2:4]\n",
    "\n",
    "merged_row_hsien_chapt2 = merged_rows_hsien_chapt2.agg(agg)\n",
    "\n",
    "original_indices_hsien_chapt2 = merged_rows_hsien_chapt2.index\n",
    "\n",
    "insert_index_hsien_chapt2 = original_indices_hsien_chapt2[0]\n",
    "\n",
    "df_dropped_hsien_chapt2 = df_hsien_chapt2.drop(original_indices_hsien_chapt2)\n",
    "\n",
    "merged_row_df_hsien_chapt2 = pd.DataFrame([merged_row_hsien_chapt2], index=[insert_index_hsien_chapt2])\n",
    "\n",
    "df_with_merged_hsien_chapt2 = pd.concat([df_dropped_hsien_chapt2.iloc[:insert_index_hsien_chapt2], merged_row_df_hsien_chapt2, df_dropped_hsien_chapt2.iloc[insert_index_hsien_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "csv_path_hsien_chapt2 = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/hsien_dataset/chapter_2_eng_version_hsien.csv'\n",
    "df_with_merged_hsien_chapt2.to_csv(csv_path_hsien_chapt2, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English_Verse_chap2_google</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Q is not unique to the name of his name, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Q is very self -esteem. All the residents of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ah Q \"was wide\", high knowledge, and \"really c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who knows that after Ah Q uses angerism, the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Well, it's bright.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ah Q became angry as usual, and he watched ang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Originally there are insurance lights here!\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"You are not worthy of ...\" At this time, it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A Q wants to be in his heart, and then he ofte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Being insects, okay? I am a worm 豸 -still not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>But although it was a worm, the idlers did not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"One hundred in the hall -one hundred and fifty!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Under such a song, A Q's money gradually enter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Two Tianmen!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>He didn't know who and why.The scolding sounde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A pile of white money! And it was him -now it'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>But he immediately defeated to win.He arranged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>He fell asleep.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           English_Verse_chap2_google\n",
       "0   A Q is not unique to the name of his name, and...\n",
       "1   A Q is very self -esteem. All the residents of...\n",
       "2   Ah Q \"was wide\", high knowledge, and \"really c...\n",
       "3   Who knows that after Ah Q uses angerism, the m...\n",
       "4                                \"Well, it's bright.\"\n",
       "5   Ah Q became angry as usual, and he watched ang...\n",
       "6   \"Originally there are insurance lights here!\" ...\n",
       "7   \"You are not worthy of ...\" At this time, it s...\n",
       "8   A Q wants to be in his heart, and then he ofte...\n",
       "9   \"Being insects, okay? I am a worm 豸 -still not...\n",
       "10  But although it was a worm, the idlers did not...\n",
       "11  \"One hundred in the hall -one hundred and fifty!\"\n",
       "12  Under such a song, A Q's money gradually enter...\n",
       "13                                     \"Two Tianmen!\"\n",
       "14  He didn't know who and why.The scolding sounde...\n",
       "15  A pile of white money! And it was him -now it'...\n",
       "16  But he immediately defeated to win.He arranged...\n",
       "17                                    He fell asleep."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#google merge\n",
    "df_google_chapt2 = pd.read_csv(\"/Users/wangxuechun/unsw/thesis-repo/Data_set/google_dataset/chapter_2_eng_version_google.csv\")\n",
    "\n",
    "#first merge\n",
    "\n",
    "merged_rows_google_chapt2 = df_google_chapt2.iloc[0:2]\n",
    "\n",
    "merged_row_google_chapt2 = merged_rows_google_chapt2.agg(agg)\n",
    "\n",
    "original_indices_google_chapt2 = merged_rows_google_chapt2.index\n",
    "\n",
    "insert_index_google_chapt2 = original_indices_google_chapt2[0]\n",
    "\n",
    "df_dropped_google_chapt2 = df_google_chapt2.drop(original_indices_google_chapt2)\n",
    "\n",
    "merged_row_df_google_chapt2 = pd.DataFrame([merged_row_google_chapt2], index=[insert_index_google_chapt2])\n",
    "\n",
    "df_with_merged_google_chapt2 = pd.concat([df_dropped_google_chapt2.iloc[:insert_index_google_chapt2], merged_row_df_google_chapt2, df_dropped_google_chapt2.iloc[insert_index_google_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "#second merge\n",
    "merged_rows_google_chapt2 = df_with_merged_google_chapt2.iloc[7:9]\n",
    "\n",
    "merged_row_google_chapt2 = merged_rows_google_chapt2.agg(agg)\n",
    "\n",
    "original_indices_google_chapt2 = merged_rows_google_chapt2.index\n",
    "\n",
    "insert_index_google_chapt2 = original_indices_google_chapt2[0]\n",
    "\n",
    "df_dropped_google_chapt2 = df_with_merged_google_chapt2.drop(original_indices_google_chapt2)\n",
    "\n",
    "merged_row_df_google_chapt2 = pd.DataFrame([merged_row_google_chapt2], index=[insert_index_google_chapt2])\n",
    "\n",
    "df_with_merged_google_chapt2 = pd.concat([df_dropped_google_chapt2.iloc[:insert_index_google_chapt2], merged_row_df_google_chapt2, df_dropped_google_chapt2.iloc[insert_index_google_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#third merge\n",
    "merged_rows_google_chapt2 = df_with_merged_google_chapt2.iloc[10:13]\n",
    "\n",
    "merged_row_google_chapt2 = merged_rows_google_chapt2.agg(agg)\n",
    "\n",
    "original_indices_google_chapt2 = merged_rows_google_chapt2.index\n",
    "\n",
    "insert_index_google_chapt2 = original_indices_google_chapt2[0]\n",
    "\n",
    "df_dropped_google_chapt2 = df_with_merged_google_chapt2.drop(original_indices_google_chapt2)\n",
    "\n",
    "merged_row_df_google_chapt2 = pd.DataFrame([merged_row_google_chapt2], index=[insert_index_google_chapt2])\n",
    "\n",
    "df_with_merged_google_chapt2 = pd.concat([df_dropped_google_chapt2.iloc[:insert_index_google_chapt2], merged_row_df_google_chapt2, df_dropped_google_chapt2.iloc[insert_index_google_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "#fourth merge\n",
    "merged_rows_google_chapt2 = df_with_merged_google_chapt2.iloc[12:14]\n",
    "\n",
    "merged_row_google_chapt2 = merged_rows_google_chapt2.agg(agg)\n",
    "\n",
    "original_indices_google_chapt2 = merged_rows_google_chapt2.index\n",
    "\n",
    "insert_index_google_chapt2 = original_indices_google_chapt2[0]\n",
    "\n",
    "df_dropped_google_chapt2 = df_with_merged_google_chapt2.drop(original_indices_google_chapt2)\n",
    "\n",
    "merged_row_df_google_chapt2 = pd.DataFrame([merged_row_google_chapt2], index=[insert_index_google_chapt2])\n",
    "\n",
    "df_with_merged_google_chapt2 = pd.concat([df_dropped_google_chapt2.iloc[:insert_index_google_chapt2], merged_row_df_google_chapt2, df_dropped_google_chapt2.iloc[insert_index_google_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "df_with_merged_google_chapt2\n",
    "\n",
    "#fifth merge\n",
    "merged_rows_google_chapt2 = df_with_merged_google_chapt2.iloc[17:19]\n",
    "\n",
    "merged_row_google_chapt2 = merged_rows_google_chapt2.agg(agg)\n",
    "\n",
    "original_indices_google_chapt2 = merged_rows_google_chapt2.index\n",
    "\n",
    "insert_index_google_chapt2 = original_indices_google_chapt2[0]\n",
    "\n",
    "df_dropped_google_chapt2 = df_with_merged_google_chapt2.drop(original_indices_google_chapt2)\n",
    "\n",
    "merged_row_df_google_chapt2 = pd.DataFrame([merged_row_google_chapt2], index=[insert_index_google_chapt2])\n",
    "\n",
    "df_with_merged_google_chapt2 = pd.concat([df_dropped_google_chapt2.iloc[:insert_index_google_chapt2], merged_row_df_google_chapt2, df_dropped_google_chapt2.iloc[insert_index_google_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "df_with_merged_google_chapt2\n",
    "\n",
    "# csv_path_google_chapt2 = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/google_dataset/chapter_2_eng_version_google.csv'\n",
    "# df_with_merged_google_chapt2.to_csv(csv_path_google_chapt2, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#julia merge\n",
    "df_julia_chapt2 = pd.read_csv(\"/Users/wangxuechun/unsw/thesis-repo/Data_set/julia_dataset/chapter_2_eng_version_julia.csv\")\n",
    "\n",
    "#first merge\n",
    "\n",
    "merged_rows_julia_chapt2 = df_julia_chapt2.iloc[0:2]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#second merge\n",
    "merged_rows_julia_chapt2 = df_with_merged_julia_chapt2.iloc[8:10]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_with_merged_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#third merge\n",
    "merged_rows_julia_chapt2 = df_with_merged_julia_chapt2.iloc[10:12]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_with_merged_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#fourth merge\n",
    "merged_rows_julia_chapt2 = df_with_merged_julia_chapt2.iloc[13:15]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_with_merged_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "\n",
    "#fifth merge\n",
    "merged_rows_julia_chapt2 = df_with_merged_julia_chapt2.iloc[18:20]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_with_merged_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "#sixth merge\n",
    "merged_rows_julia_chapt2 = df_with_merged_julia_chapt2.iloc[20:22]\n",
    "\n",
    "merged_row_julia_chapt2 = merged_rows_julia_chapt2.agg(agg)\n",
    "\n",
    "original_indices_julia_chapt2 = merged_rows_julia_chapt2.index\n",
    "\n",
    "insert_index_julia_chapt2 = original_indices_julia_chapt2[0]\n",
    "\n",
    "df_dropped_julia_chapt2 = df_with_merged_julia_chapt2.drop(original_indices_julia_chapt2)\n",
    "\n",
    "merged_row_df_julia_chapt2 = pd.DataFrame([merged_row_julia_chapt2], index=[insert_index_julia_chapt2])\n",
    "\n",
    "df_with_merged_julia_chapt2 = pd.concat([df_dropped_julia_chapt2.iloc[:insert_index_julia_chapt2], merged_row_df_julia_chapt2, df_dropped_julia_chapt2.iloc[insert_index_julia_chapt2:]]).sort_index().reset_index(drop=True)\n",
    "\n",
    "csv_path_julia_chapt2 = f'/Users/wangxuechun/unsw/thesis-repo/Data_set/julia_dataset/chapter_2_eng_version_julia.csv'\n",
    "df_with_merged_julia_chapt2.to_csv(csv_path_julia_chapt2, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
